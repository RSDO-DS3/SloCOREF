{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Slovene coreference resolution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsJnUG1dIQov",
        "colab_type": "text"
      },
      "source": [
        "# Coreference resolution for Slovene language\n",
        "\n",
        "You can find the source code of this project in the GitHub [repository](https://github.com/matejklemen/slovene-coreference-resolution).\n",
        "\n",
        "This notebook serves as instructions on how to use the provided source code and can also be **run in a Google Colab** environment (it is actually preferred you do so).\n",
        "\n",
        "Our work includes four different models:\n",
        "\n",
        "- the baseline model (including evaluation of trivial models),\n",
        "- non-contextual model (with word2vec embeddings),\n",
        "- contextual model with ELMo embeddings,\n",
        "- contextual model with BERT embeddings.\n",
        "\n",
        "Note that if you want to run only one of the models, you **do not need to run all the cells in this notebook**. \n",
        "For example, if you are interested in running the contextual model with ELMo, you probably do not need the pre-trained BERT or word2vec embeddings.\n",
        "\n",
        "Contents of the notebook are as follows:\n",
        "\n",
        "1. fetching the source code of our work,\n",
        "\n",
        "2. obtaining the datasets,\n",
        "\n",
        "3. obtaining the pre-trained data,\n",
        "\n",
        "4. running the models (evaluation of pre-trained models or training new models)\n",
        "\n",
        "**Note:** if you are running this in Google Colab, do not forget to set Runtime type to GPU by navigating to *Runtime* menu -> *Change runtime type* -> make sure that *GPU* is selected in the dropdown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTi2uY74Nu9-",
        "colab_type": "text"
      },
      "source": [
        "# 1. Fetching source code\n",
        "\n",
        "First of all, fetch the source code from the repository and install the needed requirements with pip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrEFphwCN2sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/matejklemen/slovene-coreference-resolution\n",
        "%cd slovene-coreference-resolution/\n",
        "!pip install -r requirements.txt -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuwTyRFxNKlv",
        "colab_type": "text"
      },
      "source": [
        "# 2. Obtaining datasets\n",
        "\n",
        "In our work we used coref149 dataset (a coreference-annotated subset of ssj500k) and SentiCoref dataset.\n",
        "\n",
        "You do not necessarily have to fetch both, but only the one you want to use for training and/or evaluation of the models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troucCo5M2ky",
        "colab_type": "text"
      },
      "source": [
        "## Coref149 & ssj500k datasets\n",
        "\n",
        "As mentioned, coref149 is a subset of documents from the ssj500k dataset, but with additional annotations of entities and coreferences. Thus we fetch both datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL3ATwldM80l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/slovene-coreference-resolution/data\n",
        "\n",
        "!wget https://www.clarin.si/repository/xmlui/bitstream/handle/11356/1182/coref149_v1.0.zip\n",
        "!unzip -q coref149_v1.0.zip -d coref149\n",
        "%rm coref149_v1.0.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAw4cWAcPCy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/slovene-coreference-resolution/data\n",
        "\n",
        "!wget https://www.clarin.si/repository/xmlui/bitstream/handle/11356/1210/ssj500k-sl.TEI.zip\n",
        "!unzip -q ssj500k-sl.TEI.zip\n",
        "%rm ssj500k-sl.TEI.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sqPfb2KPPj3",
        "colab_type": "text"
      },
      "source": [
        "Since we only need a subset of the whole ssj500k, there's a python script in the repository that produces a \"reduced\" ssj500k dataset, containing only the documents also existing in the coref149."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wdf7ZzwPOcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/slovene-coreference-resolution\n",
        "\n",
        "# Trim SSJ500k dataset to decrease size/improve loading speed\n",
        "!python src/trim_ssj.py --coref149_dir=data/coref149 \\\n",
        "    --ssj500k_path=data/ssj500k-sl.TEI/ssj500k-sl.body.xml \\\n",
        "    --target_path=data/ssj500k-sl.TEI/ssj500k-sl.body.reduced.xml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba8dl3nIM87e",
        "colab_type": "text"
      },
      "source": [
        "## SentiCoref"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW1kxbvYNFFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/slovene-coreference-resolution/data\n",
        "\n",
        "!wget https://www.clarin.si/repository/xmlui/bitstream/handle/11356/1285/SentiCoref_1.0.zip\n",
        "!unzip -q SentiCoref_1.0.zip -d senticoref1_0\n",
        "%rm SentiCoref_1.0.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dM-ck7MNFMQ",
        "colab_type": "text"
      },
      "source": [
        "## 3. Obtaining pre-trained data\n",
        "\n",
        "With the datasets obtained, it's time to obtain pre-trained data. That includes:\n",
        "\n",
        "- pre-trained models we made as a part of our work (those can be immediately evaluated without training)\n",
        "- pre-trained base data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt_Juc_HbbLe",
        "colab_type": "text"
      },
      "source": [
        "### Pre-trained models (from our work)\n",
        "\n",
        "This section is relevant only **if you want to evaluate pre-trained models** we prepared in our work. If you are interested in training models from scratch, skip to the next section.\n",
        "\n",
        "Pretrained models are available at the following Google Drive link:\n",
        "\n",
        "https://drive.google.com/open?id=15xKYqSy5WgedFIPGP-HZz7YVmZa6oKg_ (~100 MB zip of all the pre-trained models).\n",
        "\n",
        "Following cells will download and extract zip into `/content/pretrained-models/`, and then copy models into appropriate places where they can be read by our source code:\n",
        "\n",
        "- baseline models go into `<repository root>/src/baseline_model/<model_name>`\n",
        "- non-contextual models go into `<repository root>/src/noncontextual_model/<model_name>`\n",
        "-contextual models (ELMo emb.) go into `<repository root>/src/contextual_model_elmo/<model_name>`\n",
        "-contextual models (BERT emb.) go into `<repository root>/src/contextual_model_bert/<model_name>`.\n",
        "\n",
        "If you are training your own models, they will as well be saved in the locations listed above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-dSi2f7mwbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir -p /content/pretrained-models/\n",
        "%cd /content/pretrained-models/\n",
        "\n",
        "!gdown --id \"15xKYqSy5WgedFIPGP-HZz7YVmZa6oKg_\"\n",
        "!unzip -q slo-coref-pretrained.zip\n",
        "%rm slo-coref-pretrained.zip\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awC-E-JFRRzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy pre-trained baseline models\n",
        "%mkdir -p /content/slovene-coreference-resolution/src/baseline_model/\n",
        "%cp -R baseline_coref149_0.05/ /content/slovene-coreference-resolution/src/baseline_model/\n",
        "%cp -R baseline_senticoref_0.005/ /content/slovene-coreference-resolution/src/baseline_model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYziPHwpSbQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy pre-trained non-contextual models\n",
        "%mkdir -p /content/slovene-coreference-resolution/src/noncontextual_model/\n",
        "%cp -R nc_w2v100_unfrozen_hs1024_senticoref_0.001_dr0.4/ /content/slovene-coreference-resolution/src/noncontextual_model/\n",
        "%cp -R nc_w2v100_unfrozen_hs512_coref149_0.001_dr0.0/ /content/slovene-coreference-resolution/src/noncontextual_model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqs7SDUzTTzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy pre-trained contextual (ELMo) models\n",
        "%mkdir -p /content/slovene-coreference-resolution/src/contextual_model_elmo/\n",
        "%cp -R elmo_coref149_lr0.005_fchs64_dr0.4/ /content/slovene-coreference-resolution/src/contextual_model_elmo/\n",
        "%cp -R elmo_senticoref_lr0.001_hs512_fchs512_dr0.6/ /content/slovene-coreference-resolution/src/contextual_model_elmo/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cum9ENMTT7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy pre-trained contextual (BERT) models\n",
        "%mkdir -p /content/slovene-coreference-resolution/src/contextual_model_bert/\n",
        "%cp -R bert_coref149_lr0.001_fchs64_dr0.4/ /content/slovene-coreference-resolution/src/contextual_model_bert/\n",
        "%cp -R bert_senticoref_lr0.001_fchs1024_seg256_dr0.2/ /content/slovene-coreference-resolution/src/contextual_model_bert/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI0b2BCLb-AM",
        "colab_type": "text"
      },
      "source": [
        "### Pre-trained base data\n",
        "\n",
        "You **must obtain these** regardless of doing training or evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD8aoRdjPkTn",
        "colab_type": "text"
      },
      "source": [
        "#### Slovene word2vec embeddings\n",
        "\n",
        "Needed only for **non-contextual model (word2vec embeddings)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWd3UlaSILhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/slovene-coreference-resolution/data\n",
        "\n",
        "!wget http://vectors.nlpl.eu/repository/20/67.zip\n",
        "!unzip -q 67.zip\n",
        "%rm 67.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SYAcF1fP1Co",
        "colab_type": "text"
      },
      "source": [
        "#### Pre-trained Slovene ELMo embeddings\n",
        "\n",
        "Needed only for **contextual model with ELMo embeddings**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hq3o1kNP4xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/slovene-coreference-resolution/data\n",
        "\n",
        "# Download pretrained Slovene ELMo\n",
        "!wget https://www.clarin.si/repository/xmlui/bitstream/handle/11356/1277/slovenian-elmo.tar.gz\n",
        "!tar -xvzf slovenian-elmo.tar.gz\n",
        "!mv slovenian slovenian-elmo\n",
        "%rm slovenian-elmo.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUw0yRPgfknN",
        "colab_type": "text"
      },
      "source": [
        "#### Pre-trained slovene BERT\n",
        "\n",
        "Needed only for training **contextual model with BERT embeddings**.\n",
        "\n",
        "https://drive.google.com/open?id=1IC9SidISzE8xAfqoZJ3lJtp3XVS1nNQQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBMuQnbkfqPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/slovene-coreference-resolution/data\n",
        "\n",
        "!gdown --id \"1IC9SidISzE8xAfqoZJ3lJtp3XVS1nNQQ\"\n",
        "!unzip -q slo-hr-en-bert-pytorch.zip\n",
        "%rm slo-hr-en-bert-pytorch.zip\n",
        "\n",
        "import os\n",
        "os.environ['CUSTOM_PRETRAINED_BERT_DIR'] = \"/content/slovene-coreference-resolution/data/slo-hr-en-bert-pytorch\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV393SGyQD_l",
        "colab_type": "text"
      },
      "source": [
        "# 4. Running the models (training/evaluation)\n",
        "\n",
        "With all the necessary data obtained, you can now actually run the models.\n",
        "Below are cells for each model that run evaluation on pre-trained models.\n",
        "\n",
        "#### Training your own models\n",
        "\n",
        "If you want to train your own models, you can take these cells as a template.\n",
        "When training, you should define a new unique model name. Running the script with **a model name that already exists will only load the model and perform evaluation**.\n",
        "\n",
        "When loading existing models, it is important that passed parameters match with the parameters of the loaded models. (Cells for the pre-trained models below are already set in that way.)\n",
        "\n",
        "**Note:** You should be in `/content/slovene-coreference-resolution/src` folder when executing below cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRJyOcMHjcp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/slovene-coreference-resolution/src"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlVdXcF-QSVa",
        "colab_type": "text"
      },
      "source": [
        "## Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dy_B-cGjD2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baseline evaluation of pre-trained model (coref149 dataset)\n",
        "!python baseline.py \\\n",
        "  --model_name=\"baseline_coref149_0.05\" \\\n",
        "  --learning_rate=\"0.05\" \\\n",
        "  --dataset=\"coref149\" \\\n",
        "  --num_epochs=\"20\" \\\n",
        "  --fixed_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2nEMVfuZOVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baseline evaluation of pre-trained model (senticoref dataset)\n",
        "!python baseline.py \\\n",
        "    --model_name=\"baseline_senticoref_0.005\" \\\n",
        "    --dataset=\"senticoref\" \\\n",
        "    --learning_rate=\"0.005\" \\\n",
        "    --num_epochs=\"50\" \\\n",
        "    --fixed_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNgm_HmdSBfw",
        "colab_type": "text"
      },
      "source": [
        "## Non-contextual model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IDbIruOSI-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Non-contextual model evaluation of pre-trained model (coref149 dataset)\n",
        "!python noncontextual_model.py \\\n",
        "    --model_name=\"nc_w2v100_unfrozen_hs512_coref149_0.001_dr0.0\" \\\n",
        "    --fc_hidden_size=\"512\" \\\n",
        "    --dropout=\"0.0\" \\\n",
        "    --learning_rate=\"0.001\" \\\n",
        "    --dataset=\"coref149\" \\\n",
        "    --embedding_size=\"100\" \\\n",
        "    --use_pretrained_embs=\"word2vec\" \\\n",
        "    --freeze_pretrained \\\n",
        "    --fixed_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIzSI88jjEgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Non-contextual model evaluation of pre-trained model (senticoref dataset)\n",
        "!python noncontextual_model.py \\\n",
        "    --model_name=\"nc_w2v100_unfrozen_hs1024_senticoref_0.001_dr0.4\" \\\n",
        "    --fc_hidden_size=\"1024\" \\\n",
        "    --dropout=\"0.4\" \\\n",
        "    --learning_rate=\"0.001\" \\\n",
        "    --dataset=\"senticoref\" \\\n",
        "    --embedding_size=\"100\" \\\n",
        "    --use_pretrained_embs=\"word2vec\" \\\n",
        "    --freeze_pretrained \\\n",
        "    --fixed_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QDyrAicShOj",
        "colab_type": "text"
      },
      "source": [
        "## Contextual model with ELMo\n",
        "\n",
        "Note: In Google Colab, do not forget to set runtime type to GPU for faster evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jejlc_6QSnPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python contextual_model_elmo.py \\\n",
        "    --model_name=\"elmo_coref149_lr0.005_fchs64_dr0.4\" \\\n",
        "    --dataset=\"coref149\" \\\n",
        "    --fc_hidden_size=\"64\" \\\n",
        "    --dropout=\"0.4\" \\\n",
        "    --learning_rate=\"0.005\" \\\n",
        "    --num_epochs=\"20\" \\\n",
        "    --freeze_pretrained \\\n",
        "    --fixed_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PvpwsJJjFIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python contextual_model_elmo.py \\\n",
        "    --model_name=\"elmo_senticoref_lr0.001_hs512_fchs512_dr0.6\" \\\n",
        "    --dataset=\"senticoref\" \\\n",
        "    --hidden_size=\"512\" \\\n",
        "    --fc_hidden_size=\"512\" \\\n",
        "    --dropout=\"0.6\" \\\n",
        "    --learning_rate=\"0.001\" \\\n",
        "    --num_epochs=\"20\" \\\n",
        "    --freeze_pretrained \\\n",
        "    --fixed_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9MzNJvwSnc-",
        "colab_type": "text"
      },
      "source": [
        "## Contextual model with BERT\n",
        "\n",
        "Note: In Google Colab, do not forget to set runtime type to GPU for faster evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFvnyLv8Ss_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python contextual_model_bert.py \\\n",
        "    --model_name=\"bert_coref149_lr0.001_fchs64_dr0.4\" \\\n",
        "    --dataset=\"coref149\" \\\n",
        "    --fc_hidden_size=\"64\" \\\n",
        "    --dropout=\"0.4\" \\\n",
        "    --learning_rate=\"0.001\" \\\n",
        "    --num_epochs=\"20\" \\\n",
        "    --freeze_pretrained \\\n",
        "    --fixed_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piIJzQtKjFu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python contextual_model_bert.py \\\n",
        "    --model_name=\"bert_senticoref_lr0.001_fchs1024_seg256_dr0.2\" \\\n",
        "    --dataset=\"senticoref\" \\\n",
        "    --fc_hidden_size=\"1024\" \\\n",
        "    --dropout=\"0.2\" \\\n",
        "    --learning_rate=\"0.001\" \\\n",
        "    --num_epochs=\"20\" \\\n",
        "    --freeze_pretrained \\\n",
        "    --fixed_split"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}