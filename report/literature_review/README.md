## Papers overview
| #  | Paper  |  Link to abstract or paper | Why is it relevant? | Additional comments (optional)
|----|---|---|---|---|
| 1. | Coreference Resolution for Slovene on Annotated Data from coref149 (Žitnik and Bajec, 2018) | [link](https://revije.ff.uni-lj.si/slovenscina2/article/view/7967) | Introduces Slovene dataset for coreference resolution and describes an approach using manual feature engineering (SkipCor).  | Potential candidate for dataset. |
| 2. | Slovene corpus for aspect-based sentiment analysis - SentiCoref 1.0 (Žitnik, 2019) | [link](https://www.clarin.si/repository/xmlui/handle/11356/1285) | Not a paper; Slovene dataset for sentiment analysis/coreference resolution (primarily the former).  | Potential candidate for dataset.  |
| 3. | End-to-end Neural Coreference Resolution (Lee et al., 2017) | [link](https://arxiv.org/abs/1707.07045) | Introduces the first attempt at end-to-end (neural) coreference resolution. "Combines" mention detection and coreference of mentions. | / |
| 4. | Higher-order Coreference Resolution with Coarse-to-fine Inference (Lee et al., 2018) | [link](https://arxiv.org/abs/1804.05392) | Improves the complexity of mention detection in previous work `(3.)` using a region proposal like mechanism. Will likely need to use something like this when doing a neural approach. | / |
| 5. | Syntactic Scaffolds for Semantic Structures (Lee et al., 2018) | [link](https://arxiv.org/abs/1808.10485) | Uses a secondary task (learning syntax properties) to improve performance on semantic role labeling and coreference resolution. | Potential improvement to be implemented (need to see what additional info could be easily incorporated). |
| 6. | Neural Models for Reasoning over Multiple Mentions using Coreference (Dhingra et al., 2018) | [link](https://arxiv.org/abs/1804.05922) | Uses contextual embeddings of current coreference clusters to improve coreference resolution. Mention as existing work on this topic in lit. review. | / |
| 7. | A Hierarchical Multi-Task Approach for Learning Embeddings from Semantic Tasks (Sanh et al., 2019) | Uses multi-task learning to improve performance on various tasks. Might be useful for getting ideas about an additional task that could improve coreference resolution. | / |
| 8. | SpanBERT: Improving Pre-training by Representing and Predicting Spans (Joshi et al., 2020) | Improves BERT by using contiguous span masking and training the span boundary representations to predict the content of the spans. | Current SOTA on OntoNotes coref. resolution dataset. |
| 9. | Neural Cross-Lingual Coreference Resolution and its Application to Entity Linking (Kundu et al., 2018) | [link](https://arxiv.org/abs/1806.10201) | Trains coreference resolution system on English and tests on Chinese and Spanish. Mention as existing work on this topic in lit. review. | / |
| 10. | Using Linguistic Features to Improve the Generalization Capability of Neural Coreference Resolvers | [link](https://arxiv.org/abs/1708.00160) | Looks at  various linguistic features and their impact on training a generalizable coreference resolution system (i.e. train on dataset#1, evaluate on dataset#2). | / |
| TBD. | Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods (Zhao et al., 2018) | [link](https://arxiv.org/abs/1804.06876) | Introduces a dataset with explicit gender bias and evaluates models to see how stereotypical they are. Mention as existing work on this topic in lit. review. | A challenging potential candidate for dataset. |
| TBD. | Linguistic Fundamentals for Natural Language Processing: 100 Essentials from Morphology and Syntax | A book on linguistic properties that could be used in NLP systems. | / |
